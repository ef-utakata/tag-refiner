# 主要AIプラットフォームにおけるテキスト生成および埋め込みモデルの技術的・経済的比較分析

本レポートは、OpenAI API、Google Gemini API、およびOllama CLIの3つの主要なAIプラットフォームが提供するテキスト生成（Completion）モデルと埋め込み（Embedding）モデルについて、その利用可能なモデル一覧、詳細なパラメータ、料金体系、主要機能、および公式ドキュメントへのリンクを網羅的に比較分析します。本分析は、AIモデルの選定、統合、または最適化を検討している技術専門家が、プロジェクトの要件に基づき最適なモデルを決定するための客観的な情報を提供することを目的としています。

## I. OpenAI API モデル

OpenAIのAPIは、多様なAIモデルを提供し、テキスト生成から埋め込み、さらにはマルチモーダルな機能までを網羅しています。その料金体系はトークン数に基づき、キャッシュされた入力には割引が適用されるなど、コスト効率を考慮した設計がなされています 1。

### 1.1. テキスト生成モデル (Completion Models) の詳細

OpenAIは、様々な用途と性能レベルに対応するテキスト生成モデルの幅広いポートフォリオを展開しています。

#### GPT-4o ファミリー (GPT-4o, GPT-4o mini)

GPT-4oファミリーは、OpenAIの多機能かつ高性能な主力モデル群です。これらのモデルは、テキストと画像の両方の入力を受け入れ、テキスト出力を生成するマルチモーダル能力を特徴としています 2。

- **モデル名（API 上の正式な識別子）**: `gpt-4o`、`gpt-4o-2024-05-13` (スナップショット)、`gpt-4o-mini` 2
- **モデルタイプ／ファミリ**: GPT-4o (Omni) シリーズ
- **用途区分**: Completion
- **最大コンテキスト長（トークン数）**: 128,000トークン 2
- **料金（1Mトークンあたり）**:
    - **GPT-4o**: 入力 $5.00、キャッシュ入力 $2.50、出力 $20.00 (テキスト)。オーディオ入力 $40.00、オーディオ出力 $80.00 1。
    - **GPT-4o mini**: 入力 $0.60、キャッシュ入力 $0.30、出力 $2.40 (テキスト)。オーディオ入力 $10.00、オーディオ出力 $20.00 1。
- **レイテンシやスループットの目安**:
    - **GPT-4o mini**: 平均レイテンシ 0.558秒、平均スループット 111.561トークン/秒。GPT-4oよりも高速に動作します 4。
    - **GPT-4o**: `gpt-4o-2024-08-06` (平均レイテンシ 0.739秒、平均レート 41.698トークン/秒)、`gpt-4o-2024-05-13` (平均レイテンシ 0.730秒、平均レート 64.069トークン/秒)、`gpt-4o-2024-11-20` (平均レイテンシ 0.676秒、平均レート 37.113トークン/秒) 4。
- **サポートされる主要機能**:
    - ストリーミング: サポート 2
    - ファインチューニング: サポート 2
    - 関数呼び出し: サポート 2
    - 構造化出力: サポート 2
    - マルチモーダル入力 (テキスト, 画像, 音声): サポート 2
    - Web検索ツール呼び出し (GPT-4o): low $30.00/1K calls, medium $35.00/1K calls, high $50.00/1K calls 1
    - Web検索ツール呼び出し (GPT-4o mini): low $25.00/1K calls, medium $27.50/1K calls, high $30.00/1K calls 1
- **公式ドキュメントへのリンク**:([https://platform.openai.com/docs/models/gpt-4o](https://platform.openai.com/docs/models/gpt-4o)) 2,([https://platform.openai.com/docs/models/gpt-4o-mini](https://platform.openai.com/docs/models/gpt-4o-mini)) 7
- **調査元URL/公開日**: 1 (2025-06-14), 2 (2024-08-06)

GPT-4oとGPT-4o miniの料金体系には大きな差異が見られます。GPT-4oはテキスト入力で1Mトークンあたり$5.00、出力で$20.00であるのに対し、GPT-4o miniはそれぞれ$0.60と$2.40と、大幅に低価格です 1。この価格差は、単なる性能の違いだけでなく、OpenAIが異なる性能とコストのニーズに対応するための意図的な製品戦略を示唆しています。GPT-4o miniが「速度で勝る」とされ 4、「費用対効果の高いワークロード」に適していると説明されていること 3は、多くの一般的なタスクにおいて、miniモデルがより経済的で実行可能な選択肢となる可能性があり、開発者の参入障壁を低減する効果が期待されます。

GPT-4oがテキストと画像の両方の入力を受け入れ、ストリーミング、関数呼び出し、構造化出力、ファインチューニングなど、多岐にわたる機能をサポートしている点 2は注目に値します。また、o4-miniがブラウジング、Python（コードインタープリター）、ファイルアップロード、画像生成といった高度なツールにアクセスできること 3は、以前のテキストのみのモデルからの明確な進歩を示しています。これらのマルチモーダルモデルをファインチューニングできる能力 2は、高度にカスタマイズされたドメイン固有のAIエージェントの開発をさらに促進するでしょう。これは、OpenAIがより汎用性の高い、エージェント対応のモデルを構築する戦略的な方向性を示唆しており、AIの応用範囲を広げる上で重要な動きです。

#### GPT-4.1 ファミリー (GPT-4.1, GPT-4.1 mini, GPT-4.1 nano)

GPT-4.1ファミリーは、GPT-4oおよびGPT-4o miniを全体的に上回る性能を持つとされており、特にコーディング、指示追従、長文コンテキスト処理において大きな進歩を遂げています 8。

- **モデル名（API 上の正式な識別子）**: `gpt-4.1`、`gpt-4.1-mini`、`gpt-4.1-nano`
- **モデルタイプ／ファミリ**: GPT-4.1 シリーズ
- **用途区分**: Completion
- **最大コンテキスト長（トークン数）**: 最大1,047,576トークン 8。1Mトークン 9。
- **料金（1Mトークンあたり）**:
    - **GPT-4.1**: 入力 $2.00、キャッシュ入力 $0.50、出力 $8.00 1。ファインチューニング: 入力 $3.00、キャッシュ入力 $0.75、出力 $12.00、トレーニング $25.00 1。
    - **GPT-4.1 mini**: 入力 $0.40、キャッシュ入力 $0.10、出力 $1.60 1。ファインチューニング: 入力 $0.80、キャッシュ入力 $0.20、出力 $3.20、トレーニング $5.00 1。
    - **GPT-4.1 nano**: 入力 $0.100、キャッシュ入力 $0.025、出力 $0.400 1。ファインチューニング: 入力 $0.20、キャッシュ入力 $0.05、出力 $0.80、トレーニング $1.50 1。
- **レイテンシやスループットの目安**:
    - **GPT-4.1 mini**: GPT-4oの約半分のレイテンシ 8。
    - **GPT-4.1 nano**: 最速のモデル 8。
- **サポートされる主要機能**:
    - ストリーミング: サポート 8
    - ファインチューニング: サポート 1
    - 関数呼び出し: サポート 8
    - バッチレスポンス: サポート 8
    - Web検索ツール呼び出し (GPT-4.1): low $30.00/1K calls, medium $35.00/1K calls, high $50.00/1K calls 1
    - Web検索ツール呼び出し (GPT-4.1 mini): low $25.00/1K calls, medium $27.50/1K calls, high $30.00/1K calls 1
    - コーディング能力大幅向上 (SWE-bench VerifiedでGPT-4oを上回る) 8
    - 指示追従能力向上 8
    - 長文理解能力向上 8
- **公式ドキュメントへのリンク**:([https://openai.com/index/gpt-4-1/](https://openai.com/index/gpt-4-1/)) 9,([https://docs.aimlapi.com/api-references/text-models-llm/openai/gpt-4.1-nano](https://docs.aimlapi.com/api-references/text-models-llm/openai/gpt-4.1-nano)) 10,([https://aimode.co/model/gpt-4-1/](https://aimode.co/model/gpt-4-1/)) 8
- **調査元URL/公開日**: 1 (2025-06-14), 8 (2025-04-23), 8 (2025-04-23)

GPT-4.1ファミリー全体が「100万トークンまでのコンテキストウィンドウ」をサポートしている点 8は、このモデル群の主要な能力を示しています。特に、これらのモデルが「エージェントの能力を大幅に向上させる」と明示的に述べられていること 9は、コンテキストの増加が単なるメモリ拡張だけでなく、より洗練された、多段階の自律的な操作を可能にするための基盤であることを示唆しています。「ツール呼び出しが30%効率的になった」という言及 9は、エージェント的な設計への注力をさらに裏付けています。これにより、大規模なコードベースの分析、複雑なドキュメントからの情報抽出、顧客サポートの自動化など、高度なタスクをより効率的に実行できる可能性が広がります。

GPT-4.1ファミリーは、標準、mini、nanoという明確な階層で提供されています 8。標準モデルは「最も有能なバージョン」であり、miniは「高性能な小型モデル」、nanoは「最小、最速、最安のモデル」と位置づけられています。それぞれの価格設定（入力1Mトークンあたり$2.00、$0.40、$0.10） 1は、コストの差別化を明確に示しています。これは、複雑な推論から分類やオートコンプリートまで、多様なユースケースに合わせて最適化するための戦略的な動きと捉えられます。開発者は、プロジェクトの特定の要件に応じて、パフォーマンスとコストの最適なバランスを選択できるようになります。

#### GPT-4 Turbo

GPT-4 Turboは、GPT-4の次世代モデルとして位置づけられ、より低コストで性能向上を目指して設計されました 11。

- **モデル名（API 上の正式な識別子）**: `gpt-4-turbo-2024-04-09`、`gpt-4-0125-preview`、`gpt-4-1106-vision-preview` 11
- **モデルタイプ／ファミリ**: GPT-4 Turbo
- **用途区分**: Completion
- **最大コンテキスト長（トークン数）**: 128,000トークン 11
- **料金（1Mトークンあたり）**: 入力 $10.00、出力 $30.00 11
- **レイテンシやスループットの目安**: 未公開 11
- **サポートされる主要機能**:
    - ストリーミング: サポート 11
    - ファインチューニング: 未サポート 11
    - 関数呼び出し: サポート 11
    - 構造化出力: 未サポート 11
    - 画像入力: サポート 11
- **公式ドキュメントへのリンク**:([https://platform.openai.com/docs/models/gpt-4-turbo](https://platform.openai.com/docs/models/gpt-4-turbo)) 11
- **調査元URL/公開日**: 11

GPT-4 Turboは、GPT-4の128,000トークンという大幅に拡張されたコンテキストウィンドウ 11と、GPT-4と比較して低価格な料金体系（入力$10.00/出力$30.00 vs GPT-4の入力$30.00/出力$60.00、いずれも1Mトークンあたり） 11が特徴です。このモデルは、より長いコンテキストを必要とするアプリケーションに対して、GPT-4よりも経済的な選択肢を提供することを目的としています。これは、OpenAIが市場のより長いコンテキストへの要求に応えるために、フラッグシップモデルの価値（より大きなコンテキスト）をより低コストで提供することを目指した、明確な製品進化を示しています。

#### GPT-4

GPT-4は、OpenAIの高知能モデルの初期バージョンです。

- **モデル名（API 上の正式な識別子）**: `gpt-4`、`gpt-4-0613`、`gpt-4-0314` 12
- **モデルタイプ／ファミリ**: GPT-4
- **用途区分**: Completion
- **最大コンテキスト長（トークン数）**: 8,192トークン 12
- **料金（1Mトークンあたり）**: 入力 $30.00、出力 $60.00 12
- **レイテンシやスループットの目安**: 未公開 12
- **サポートされる主要機能**:
    - ストリーミング: サポート 12
    - ファインチューニング: サポート 12
    - 関数呼び出し: 未サポート 12。ただし、Web検索ツール呼び出しはサポートされる場合があります 1。
- **公式ドキュメントへのリンク**:([https://platform.openai.com/docs/models/gpt-4](https://platform.openai.com/docs/models/gpt-4)) 12
- **調査元URL/公開日**: 12

GPT-4は「古いバージョンの高知能GPTモデル」と表現されており 12、8,192トークンのコンテキストウィンドウを持ちます。ストリーミングとファインチューニングはサポートされていますが、関数呼び出しは直接的にはサポートされていません 12。ただし、Web検索ツール呼び出しをサポートする可能性が示唆されており 1、これはAPIのバージョンやツールの定義による差異の可能性を示唆しています。このモデルは、後続のTurboやoシリーズモデルに比べて高価であり、より新しいモデルへの移行が推奨されています 11。

#### GPT-3.5 Turbo

GPT-3.5 Turboは、OpenAIのコスト効率の高いモデルであり、幅広いタスクに利用されています。

- **モデル名（API 上の正式な識別子）**: `gpt-3.5-turbo`、`gpt-3.5-turbo-0125` 13、`gpt-3.5-turbo-0613` 14、`gpt-3.5-turbo-16k` 14
- **モデルタイプ／ファミリ**: GPT-3.5 Turbo
- **用途区分**: Completion
- **最大コンテキスト長（トークン数）**: 16,385トークン 13。`gpt-3.5-turbo-16k`は4kベースモデルの4倍のコンテキスト長 14。
- **料金（1Mトークンあたり）**:
    - `gpt-3.5-turbo-0125`: 入力 $0.50、出力 $1.50 13
    - `gpt-3.5-turbo-0613`: 入力 $1.50 (25%コスト削減)、出力 未公開 14
    - `gpt-3.5-turbo-16k`: 入力 $3.00、出力 $4.00 14
- **レイテンシやスループットの目安**: 平均レイテンシ 0.571秒、平均スループット 63.459トークン/秒 4
- **サポートされる主要機能**:
    - ストリーミング: サポート 14
    - ファインチューニング: 未サポート 13。ただし、ファインチューニングモデルの料金が記載されており、GPT-3.5 Turboも対象に含まれる可能性はあります 15。
    - 関数呼び出し: サポート 14
    - システムメッセージによる制御性向上 14
- **公式ドキュメントへのリンク**:([https://docsbot.ai/models/gpt-3-5-turbo](https://docsbot.ai/models/gpt-3-5-turbo)) 13
- **調査元URL/公開日**: 13 (2024-01-24), 14 (2023-06-14), 4 (2024-08-06)

GPT-3.5 Turboは、その低価格と機能サポートにより、多くの開発者にとって魅力的な選択肢であり続けています。特に、`gpt-3.5-turbo-16k`の導入により、より長いコンテキストを低コストで利用できるようになったことは、アプリケーション開発の柔軟性を高めています 14。入力トークンの25%コスト削減 14と関数呼び出しのサポート 14は、OpenAIが強力な機能をより手頃な価格で利用できるようにし、より広範な採用を促進する戦略を示しています。これは、特に予算に制約のあるプロジェクトや、大量の処理を必要とするアプリケーションにとって、非常に重要な要素となります。

#### o-シリーズ (o3, o4-mini)

o-シリーズモデルは、複雑な多段階の問題解決に特化した推論モデルです。

- **モデル名（API 上の正式な識別子）**: `o3`、`o4-mini`、`o3-mini` 3
- **モデルタイプ／ファミリ**: o-シリーズ (推論モデル)
- **用途区分**: Completion
- **最大コンテキスト長（トークン数）**: 200,000トークン 3
- **料金（1Mトークンあたり）**:
    - **o3**: 入力 $2.00、キャッシュ入力 $0.50、出力 $8.00 1
    - **o4-mini**: 入力 $1.100、キャッシュ入力 $0.275、出力 $4.400 1。ファインチューニング: 入力 $4.00、キャッシュ入力 $1.00、出力 $16.00、トレーニング $100.00/トレーニング時間 1。
- **レイテンシやスループットの目安**:
    - **o3-mini**: o1-miniより24%高速 (平均応答時間 7.7秒 vs 10.16秒) 17。
    - **o4-mini**: o3-miniより高速な平均レイテンシと高いスループット上限 3。
- **サポートされる主要機能**:
    - ストリーミング: サポート 3
    - ファインチューニング: o4-miniはサポート 3。o3/o3-miniは未サポート 16。
    - 関数呼び出し: サポート 3
    - JSONモード: サポート 3
    - システムメッセージ: サポート 16
    - 推論努力オプション (low, medium, high): o3-miniでサポート 17。o4-miniでも継承 3。
    - マルチモーダル入力 (画像): o4-miniでサポート 3。o3-miniは未サポート 17。
    - 高度なChatGPTツール (ブラウジング, Python, ファイルアップロード, 画像生成, メモリ): o4-miniでアクセス可能 3。
- **公式ドキュメントへのリンク**: [o3/o4-mini FAQ](https://help.openai.com/en/articles/9855712-chatgpt-openai-o3-and-o4-mini-models-faq-enterprise-edu-version) 16, [o3-mini](https://openai.com/index/openai-o3-mini/) 17, [o4-mini](https://help.openai.com/en/articles/10491870-o4-mini-in-chatgpt-faq) 3
- **調査元URL/公開日**: 1 (2025-06-14), 3 (2024-04-24), 1 (2025-06-14), 16

o-シリーズは、OpenAIの推論能力の最前線を代表するモデル群です。o3は「最も強力な推論モデル」と表現され、o4-miniは「OpenAIの最新の小型推論モデル」と位置づけられています 16。o3-miniが持つ「優れたSTEM能力」と、ユーザーが「低、中、高」の3つの推論努力オプションを選択できる機能 17は、単なる一般的な知能に関するものではなく、モデルがどのように「考える」かを明示的に訓練し、そのプロセスをユーザーが制御できるようにすることに関するものです。これは、高リスクなアプリケーションにおいて重要な、より解釈可能で制御可能なAI出力を目指す動きを示唆しています。

o4-miniはo3-miniを基盤とし、マルチモーダルおよびツール機能を追加しており 3、o4-miniがo3-miniを段階的に置き換えることが示唆されています。この迅速なイテレーションと、マルチモーダル入力や複雑なツール使用などの高度な機能が、より小型で費用対効果の高いモデルに移行していること 1は、OpenAIが最先端のAI機能を広く利用可能かつ効率的にすることに強く取り組んでいることを示唆しており、「ミニ」モデルが何ができるかの限界を押し広げています。これは、より多くの開発者が高度なAI機能を活用し、革新的なアプリケーションを構築することを可能にするでしょう。

### Table 1: OpenAI API テキスト生成モデル一覧

|   |   |   |   |   |   |   |   |   |   |
|---|---|---|---|---|---|---|---|---|---|
|**モデル名**|**モデルタイプ／ファミリ**|**最大コンテキスト長（トークン）**|**料金（入力 $/1Mトークン）**|**料金（出力 $/1Mトークン）**|**ストリーミング**|**ファインチューニング**|**関数呼び出し**|**公式ドキュメントリンク**|**調査元URL/公開日**|
|gpt-4o|GPT-4o|128,000|5.00 (テキスト), 40.00 (オーディオ)|20.00 (テキスト), 80.00 (オーディオ)|◯|◯|◯|[Link](https://platform.openai.com/docs/models/gpt-4o)|1|
|gpt-4o mini|GPT-4o mini|128,000|0.60 (テキスト), 10.00 (オーディオ)|2.40 (テキスト), 20.00 (オーディオ)|◯|◯|◯|[Link](https://platform.openai.com/docs/models/gpt-4o-mini)|1|
|gpt-4.1|GPT-4.1|1,047,576|2.00|8.00|◯|◯|◯|[Link](https://openai.com/index/gpt-4-1/)|1|
|gpt-4.1 mini|GPT-4.1 mini|1,047,576|0.40|1.60|◯|◯|◯|[Link](https://aimode.co/model/gpt-4-1/)|1|
|gpt-4.1 nano|GPT-4.1 nano|1,047,576|0.100|0.400|◯|◯|◯|[Link](https://docs.aimlapi.com/api-references/text-models-llm/openai/gpt-4.1-nano)|1|
|gpt-4-turbo|GPT-4 Turbo|128,000|10.00|30.00|◯|×|◯|[Link](https://platform.openai.com/docs/models/gpt-4-turbo)|11|
|gpt-4|GPT-4|8,192|30.00|60.00|◯|◯|×|[Link](https://platform.openai.com/docs/models/gpt-4)|12|
|gpt-3.5-turbo|GPT-3.5 Turbo|16,385|0.50 (0125), 1.50 (0613), 3.00 (16k)|1.50 (0125), 未公開 (0613), 4.00 (16k)|◯|未公開 (一部可能？)|◯|[Link](https://docsbot.ai/models/gpt-3-5-turbo)|13|
|o3|o-series|200,000|2.00|8.00|◯|×|◯|[Link](https://help.openai.com/en/articles/9855712-chatgpt-openai-o3-and-o4-mini-models-faq-enterprise-edu-version)|1|
|o4-mini|o-series|200,000|1.100|4.400|◯|◯|◯|[Link](https://help.openai.com/en/articles/10491870-o4-mini-in-chatgpt-faq)|1|

### 1.2. 埋め込みモデル (Embedding Models) の詳細

OpenAIの埋め込みモデルは、テキストデータをベクトル空間に変換し、類似性検索やクラスタリングなどのタスクを可能にします。

#### text-embedding-3-large, text-embedding-3-small, text-embedding-ada-002

- **モデル名（API 上の正式な識別子）**: `text-embedding-3-large`、`text-embedding-3-small`、`text-embedding-ada-002`
- **モデルタイプ／ファミリ**: Embedding
- **用途区分**: Embedding
- **最大コンテキスト長（トークン数）**: 8,191トークン 19
- **埋め込みベクトル次元数**:
    - **text-embedding-3-large**: 3072次元 (デフォルト)。256次元または1024次元にトリミング可能 19。
    - **text-embedding-3-small**: 1536次元 (デフォルト)。512次元にトリミング可能 19。
    - **text-embedding-ada-002**: 1536次元 19。
- **料金（1Mトークンあたり）**:
    - **text-embedding-3-small**: $0.02 15
    - **text-embedding-3-large**: $0.13 15
    - **ada v2**: $0.10 15
- **レイテンシやスループットの目安**: 未公開
- **サポートされる主要機能**: Matryoshka Representation Learning (MRL) による次元削減 19
- **公式ドキュメントへのリンク**: [OpenAI API Pricing](https://openai.com/api/pricing/) 1,([https://www.pinecone.io/learn/openai-embeddings-v3/](https://www.pinecone.io/learn/openai-embeddings-v3/)) 19
- **調査元URL/公開日**: 1 (2025-06-14), 15

OpenAIの埋め込みモデルは、Matryoshka Representation Learning（MRL）という技術を導入し、埋め込みベクトルの次元削減を可能にしています 19。これにより、`text-embedding-3-large`は3072次元から256次元にトリミングされても、`ada-002`（1536次元）を上回る性能を発揮できるとされています 19。この革新は、ベクトルデータベースの管理（ストレージと検索コスト/速度）における主要な課題に直接対処し、大規模AIシステム向けの実用的な、本番環境対応ソリューションに焦点を当てていることを示しています。次元削減は、特に大規模な検索システムにおいて、ストレージコストとレイテンシを大幅に削減する可能性を秘めています。

これらの新しい埋め込みモデルは、特に多言語対応において大きな性能向上を遂げています。MIRACLベンチマークでは、31.4%から54.9%への飛躍的な改善が報告されています 19。これは、グローバルなユーザーベースをターゲットとするアプリケーションや、堅牢な多言語検索/取得を必要とするアプリケーションにとって、v3モデルが大幅なアップグレードであることを意味します。OpenAIの埋め込みサービスが、より広範な市場ニーズに対応できるよう進化していることを示唆しています。

### Table 2: OpenAI API 埋め込みモデル一覧

|   |   |   |   |   |   |   |
|---|---|---|---|---|---|---|
|**モデル名**|**モデルタイプ／ファミリ**|**埋め込みベクトル次元数**|**最大コンテキスト長（トークン）**|**料金（$/1Mトークン）**|**公式ドキュメントリンク**|**調査元URL/公開日**|
|text-embedding-3-large|Embedding|3072 (デフォルト, 256/1024にトリミング可)|8,191|0.13|[Link](https://openai.com/api/pricing/)|15|
|text-embedding-3-small|Embedding|1536 (デフォルト, 512にトリミング可)|8,191|0.02|[Link](https://openai.com/api/pricing/)|15|
|text-embedding-ada-002|Embedding|1536|8,191|0.10|[Link](https://openai.com/api/pricing/)|15|

### 1.3. OpenAI API モデルの共通機能と料金体系の概要

OpenAI APIは、モデル固有の機能に加えて、開発者がアプリケーションを構築し最適化するための共通の機能と料金体系を提供しています。

- **料金計算**: 料金はトークン数に基づいて計算され 1、ツール固有のモデルにはツール呼び出しあたりの料金が設定されています 1。また、キャッシュされた入力には割引が適用されます 1。
- **バッチAPI**: 大規模な非同期タスク向けに、入力と出力で50%の割引が提供されます 1。
- **Responses API**: Chat Completionsと組み込みツール使用を統合し、簡素化された開発体験を提供します 1。
- **Assistants API**: ツールを備えたアシスタント体験を構築するためのAPIです 1。
- **組み込みツール**:
    - Code Interpreter: $0.03 1
    - File Search Storage: $0.10 / GB/日 (最初のGBは無料) 1
    - File Search Tool Call: $2.50 / 1K呼び出し (Responses APIのみ) 1
    - Web Search Tool Call: モデルと検索コンテキストサイズに依存します 1。
- **レイテンシ最適化の原則**: 推論速度を向上させるための7つの原則が示されています。これには、トークン処理の高速化、生成トークン数の削減、入力トークン数の削減、リクエスト数の削減、並列化、ストリーミング、段階的な表示、ロード状態の表示などが含まれます 21。特にストリーミングは、ユーザーの待ち時間を大幅に短縮する最も効果的なアプローチとされています 21。
- **ファインチューニング**: データセットのアップロード、ハイパーパラメータ設定、ジョブ作成を通じてモデルのファインチューニングが可能です 5。ただし、一部のモデルではまだサポートされていません 11。ファインチューニングされたモデルでの関数呼び出しの信頼性に関する課題も報告されています 22。
- **公式ドキュメントへのリンク**: [OpenAI API Pricing](https://openai.com/api/pricing/) 1,(https://platform.openai.com/docs/models/gpt-4o) 2, [Latency Optimization Guide](https://platform.openai.com/docs/guides/latency-optimization/example) 21
- **調査元URL/公開日**: 1 (2025-06-14), 22 (2023-10-09), 5 (2025-04-23), 3 (2024-04-24), 4 (2024-08-06), 21

OpenAIのAPI設計は、エージェントワークフローへの移行を強く意識しています。Responses APIがチャット補完とアシスタントの組み込みツール使用を組み合わせている点 1や、GPT-4oの関数呼び出しサポート 2、GPT-4.1のツール呼び出し効率の向上 9、o4-miniの拡張されたツールセット 3は、OpenAIが単純なプロンプト応答のインタラクションを超えて、より洗練された、多段階の、自律的なAIシステムを可能にする方向へと戦略的にシフトしていることを示しています。これは、AIがより複雑なタスクを自律的に実行する未来に向けた重要なステップです。

また、プラットフォームはパフォーマンス最適化とコスト管理に関する包括的なガイダンスを提供しています 21。レイテンシ最適化のための「7つの原則」や、入力とキャッシュ入力の料金を区別する料金体系 1、バッチAPIでの割引 1は、OpenAIがエンタープライズレベルのデプロイメントにおける課題を予測し、対処している成熟したプラットフォームであることを示しています。これにより、開発者は効率的かつコスト効果的に大規模なAIソリューションを構築できるようになります。

## II. Google Gemini API モデル

Google Gemini APIは、マルチモーダルな機能と大規模なコンテキストウィンドウを特徴とするモデル群を提供しています。料金体系はモデルやコンテキスト長によって変動し、思考トークンに対する課金など、ユニークな側面も持ち合わせています。

### 2.1. テキスト生成モデル (Completion Models) の詳細

Google Gemini APIのテキスト生成モデルは、特にマルチモーダルな入力処理と大規模なコンテキスト長に強みを持っています。

#### Gemini 2.5 ファミリー (Flash Preview, Pro Preview)

Gemini 2.5ファミリーは、Googleの最新かつ最も高性能なモデル群であり、特に複雑な推論タスクとマルチモーダルな理解に優れています。

- **モデル名（API 上の正式な識別子）**: `gemini-2.5-flash-preview-05-20`、`gemini-2.5-pro-preview-06-05`
- **モデルタイプ／ファミリ**: Gemini 2.5
- **用途区分**: Completion
- **最大コンテキスト長（トークン数）**:
    - **Gemini 2.5 Flash Preview**: 1Mトークン 23
    - **Gemini 2.5 Pro Preview**: 1Mトークン 23。ただし、料金は200kトークン超で変動。
- **料金（1Mトークンあたり）**:
    - **Gemini 2.5 Flash Preview**:
        - 入力: $0.15 (テキスト/画像/動画)、$1.00 (音声) 23
        - 出力: 非思考 $0.60、思考 $3.50 23
        - コンテキストキャッシュ: $0.0375 (テキスト/画像/動画)、$0.25 (音声)、$1.00 / 1Mトークン/時間 23
    - **Gemini 2.5 Pro Preview**:
        - 入力: $1.25 (プロンプト <= 200kトークン)、$2.50 (プロンプト > 200kトークン) 23
        - 出力 (思考トークン含む): $10.00 (プロンプト <= 200kトークン)、$15.00 (プロンプト > 200kトークン) 23
        - コンテキストキャッシュ: $0.31 (プロンプト <= 200kトークン)、$0.625 (プロンプト > 200kトークン)、$4.50 / 1Mトークン/時間 23
- **レイテンシやスループットの目安**:
    - **Gemini 2.5 Pro Preview**: 100Kトークンで約2分、500Kトークンで10分以上かかる場合があります 24。
    - **Gemini 2.5 Flash / Pro**: 2Kトークンで平均15秒かかる場合があります 24。
- **サポートされる主要機能**:
    - ストリーミング: 未公開 23。ただし、Gemini 2.0 Flash Liveで双方向音声/動画インタラクションが言及 25。
    - ファインチューニング: 未サポート 23。
    - 関数呼び出し: サポート 26。
    - 思考予算 (Thinking Budget): サポート 23。
    - Google Searchとの連携 (Grounding): サポート 23。
    - マルチモーダル入力 (音声, 画像, 動画, テキスト): サポート 25。
- **公式ドキュメントへのリンク**: [Gemini API Pricing](https://ai.google.dev/gemini-api/docs/pricing) 23, [Gemini 2.5 Flash Preview](https://aistudio.google.com?model=gemini-2.5-flash-preview-05-20) 23, [Gemini 2.5 Pro Preview](https://aistudio.google.com?model=gemini-2.5-pro-preview-06-05) 23
- **調査元URL/公開日**: 23 (2025-06-06), 23 (2025-06-06), 24

Gemini 2.5 Flash Previewの料金体系には、「出力価格：非思考：$0.60 思考：$3.50」という「思考」トークンに対する明確な課金メカニズムが導入されています 23。これは、モデルが内部で複雑な推論ステップを実行した場合にのみ追加コストが発生することを意味します。この粒度の高いコスト制御は、開発者が複雑な問題解決が本当に必要な場合にのみ「思考」コストを発生させ、単純な生成タスクでは発生させないことで、コストを最適化できることを可能にします。モデルの認知プロセスに対するこの制御は、エージェントアプリケーションの効率性に焦点を当てたGoogleのユニークな機能であり、重要な技術的特徴です。

Gemini 2.5 Flash Previewは100万トークン、Gemini 1.5 Proは200万トークンという大規模なコンテキストウィンドウをサポートしています 23。これは市場における明確な差別化要因です。Gemini 2.5 Pro Previewの料金は、200kトークンを超えるプロンプトで価格が上昇する段階的な料金体系を採用しています（入力1Mトークンあたり$1.25から$2.50、出力1Mトークンあたり$10.00から$15.00） 23。この段階的な料金体系は、非常に大きなコンテキスト内でコンテンツを処理および生成するために必要な計算リソースの増加を直接反映しており、極端なコンテキスト使用のコストへの影響を明確にしています。これにより、開発者は大規模なコンテキストを活用する際のコスト構造をより正確に把握し、最適化を図ることができます。

#### Gemini 2.0 ファミリー (Flash, Flash-Lite)

Gemini 2.0ファミリーは、エージェント時代のために構築された、バランスの取れたマルチモーダルモデルです。

- **モデル名（API 上の正式な識別子）**: `gemini-2.0-flash`、`gemini-2.0-flash-lite`
- **モデルタイプ／ファミリ**: Gemini 2.0
- **用途区分**: Completion
- **最大コンテキスト長（トークン数）**:
    - **Gemini 2.0 Flash**: 1Mトークン 23
    - **Gemini 2.0 Flash-Lite**: 未公開 23
- **料金（1Mトークンあたり）**:
    - **Gemini 2.0 Flash**:
        - 入力: $0.10 (テキスト/画像/動画)、$0.70 (音声) 23
        - 出力: $0.40 23
        - コンテキストキャッシュ: $0.025 / 1Mトークン (テキスト/画像/動画)、$0.175 / 1Mトークン (音声) 23
        - コンテキストキャッシュ (ストレージ): $1.00 / 1Mトークン/時間 23
        - 画像生成: $0.039 / 画像 23
    - **Gemini 2.0 Flash-Lite**:
        - 入力: $0.075 23
        - 出力: $0.30 23
- **レイテンシやスループットの目安**:
    - Gemini 2.0 Flash / Flash-Lite: 2Kトークンで平均15秒かかる場合があります 24。
    - Gemini 2.0 Flash Live: 低レイテンシの双方向音声・動画インタラクションに対応 25。
- **サポートされる主要機能**:
    - ストリーミング: Gemini 2.0 Flashはリアルタイムストリーミングをサポート 25。Gemini 2.0 Flash Liveは低レイテンシの双方向音声・動画インタラクションに対応 25。
    - ファインチューニング: 未サポート 23。
    - 関数呼び出し: サポート 26。
    - Google Searchとの連携 (Grounding): サポート 23。
    - マルチモーダル入力 (音声, 画像, 動画, テキスト): サポート 25。
- **公式ドキュメントへのリンク**: [Gemini API Pricing](https://ai.google.dev/gemini-api/docs/pricing) 23, [Gemini 2.0 Flash](https://aistudio.google.com?model=gemini-2.0-flash) 23, [Gemini 2.0 Flash-Lite](https://aistudio.google.com?model=gemini-2.0-flash-lite) 23
- **調査元URL/公開日**: 23 (2025-06-06), 23 (2025-06-06), 25 (2025-06-09), 24

Gemini 2.0 Flashは、100万トークンのコンテキストウィンドウと、テキスト/画像/動画入力で1Mトークンあたり$0.10、音声入力で$0.70という低価格な料金設定が特徴です 23。Gemini 2.0 Flash-Liteはさらに低価格な$0.075（入力）と$0.30（出力）を提供しており 23、「費用対効果と低レイテンシ」に最適化されています 25。この価格競争力のある設定は、GoogleがAIモデルの利用を民主化し、より広範なアプリケーションでの採用を促進しようとしていることを示唆しています。特に、大規模なデータ処理やリアルタイムインタラクションを必要とするアプリケーションにとって、これらのモデルは魅力的な選択肢となるでしょう。

Gemini 2.0 Flashは「次世代機能、速度、思考、リアルタイムストリーミング」に最適化されていると明記されており 25、Gemini 2.0 Flash Liveは「低レイテンシの双方向音声・動画インタラクション」をサポートしています 25。これらの機能は、GoogleがリアルタイムかつインタラクティブなAIアプリケーションの提供に注力していることを示しています。特に、音声や動画を介したマルチモーダルなインタラクションは、ユーザー体験を根本的に変える可能性を秘めており、エージェントやバーチャルアシスタントの分野で重要な役割を果たすことが期待されます。

#### Gemini 1.5 Pro

Gemini 1.5 Proは、GoogleのGemini 1.5シリーズにおける最高知能モデルであり、特に大規模なコンテキスト処理に強みを持っています。

- **モデル名（API 上の正式な識別子）**: `gemini-1.5-pro`
- **モデルタイプ／ファミリ**: Gemini 1.5 Pro
- **用途区分**: Completion
- **最大コンテキスト長（トークン数）**: 2Mトークン 23
- **料金（1Mトークンあたり）**:
    - 入力: $1.25 (プロンプト <= 128kトークン)、$2.50 (プロンプト > 128kトークン) 23
    - 出力: $5.00 (プロンプト <= 128kトークン)、$10.00 (プロンプト > 128kトークン) 23
    - コンテキストキャッシュ: $0.3125 (プロンプト <= 128kトークン)、$0.625 (プロンプト > 128kトークン) 23
    - コンテキストキャッシュ (ストレージ): $4.50 / 時間 23
- **レイテンシやスループットの目安**: 100Kトークンで約2分、500Kトークンで10分以上かかる場合があります 24。
- **サポートされる主要機能**:
    - ストリーミング: 未公開 23。
    - ファインチューニング: 未サポート 23。
    - 関数呼び出し: サポート 26。
    - Google Searchとの連携 (Grounding): サポート 23。
    - マルチモーダル入力 (音声, 画像, 動画, テキスト): サポート 25。
- **公式ドキュメントへのリンク**: [Gemini API Pricing](https://ai.google.dev/gemini-api/docs/pricing) 23, [Gemini 1.5 Pro](https://aistudio.google.com?model=gemini-1.5-pro) 23
- **調査元URL/公開日**: 23 (2025-06-06), 23 (2025-06-06), 24

Gemini 1.5 Proは、その「画期的な200万トークンのコンテキストウィンドウ」 23により、非常に大規模なドキュメントやデータセットを一度に処理できる能力を提供します。これは、長文の要約、複雑なデータ分析、広範な知識ベースからの情報検索など、高度なタスクにおいて極めて有利です。ただし、この大規模なコンテキストを処理する際には、レイテンシが非常に高くなる可能性があることが報告されています（100Kトークンで約2分、500Kトークンで10分以上） 24。このレイテンシの課題は、リアルタイムアプリケーションでの利用を検討する際に重要な考慮事項となります。

Gemini 1.5 Proの料金体系は、プロンプトの長さによって変動します（128kトークンを超えるプロンプトでは入力と出力の料金が上昇） 23。これは、非常に大きなコンテキストを利用する際の計算コストの増加を反映しています。このモデルが「複雑な推論タスク」に最適化されていること 25は、その高い知能と大規模なコンテキスト処理能力が、特にデータサイエンス、研究、高度なビジネスインテリジェンスなどの分野で価値を発揮することを示唆しています。

### Table 3: Google Gemini API テキスト生成モデル一覧

|   |   |   |   |   |   |   |   |   |   |
|---|---|---|---|---|---|---|---|---|---|
|**モデル名**|**モデルタイプ／ファミリ**|**最大コンテキスト長（トークン）**|**料金（入力 $/1Mトークン）**|**料金（出力 $/1Mトークン）**|**ストリーミング**|**ファインチューニング**|**関数呼び出し**|**公式ドキュメントリンク**|**調査元URL/公開日**|
|gemini-2.5-flash-preview-05-20|Gemini 2.5 Flash Preview|1,000,000|0.15 (テキスト/画像/動画), 1.00 (音声)|0.60 (非思考), 3.50 (思考)|未公開|×|◯|[Link](https://ai.google.dev/gemini-api/docs/pricing)|23|
|gemini-2.5-pro-preview-06-05|Gemini 2.5 Pro Preview|1,000,000|1.25 (<=200k), 2.50 (>200k)|10.00 (<=200k), 15.00 (>200k)|未公開|×|◯|[Link](https://ai.google.dev/gemini-api/docs/pricing)|23|
|gemini-2.0-flash|Gemini 2.0 Flash|1,000,000|0.10 (テキスト/画像/動画), 0.70 (音声)|0.40|◯|×|◯|[Link](https://ai.google.dev/gemini-api/docs/pricing)|23|
|gemini-2.0-flash-lite|Gemini 2.0 Flash-Lite|未公開|0.075|0.30|未公開|×|未公開|[Link](https://ai.google.dev/gemini-api/docs/pricing)|23|
|gemini-1.5-pro|Gemini 1.5 Pro|2,000,000|1.25 (<=128k), 2.50 (>128k)|5.00 (<=128k), 10.00 (>128k)|未公開|×|◯|[Link](https://ai.google.dev/gemini-api/docs/pricing)|23|

### 2.2. 埋め込みモデル (Embedding Models) の詳細

Google Gemini APIは、テキスト埋め込みのための専用モデルも提供しています。

#### Text Embedding 004 (gemini-embedding-001)

- **モデル名（API 上の正式な識別子）**: `gemini-embedding-001` (Text Embedding 004)
- **モデルタイプ／ファミリ**: Embedding
- **用途区分**: Embedding
- **最大コンテキスト長（トークン数）**: 2048トークン 28
- **埋め込みベクトル次元数**: 最大3072次元 28。ユーザーは`output_dimensionality`パラメータで次元数を制御可能 28。
- **料金（1Mトークンあたり）**: 未公開 (有料ティアの入力/出力料金は明示されていない) 23。
- **レイテンシやスループットの目安**: 未公開
- **サポートされる主要機能**:
    - 多言語対応: 英語、多言語、コードタスクで最先端の性能 28。
    - タスクタイプ選択: `RETRIEVAL_QUERY`, `RETRIEVAL_DOCUMENT`, `SEMANTIC_SIMILARITY`, `CLASSIFICATION`, `CLUSTERING`, `QUESTION_ANSWERING`, `FACT_VERIFICATION`, `CODE_RETRIEVAL_QUERY` 29。
    - 自動切り捨て (`autoTruncate`): トークン制限を超えたテキストの自動切り捨てを制御可能 29。
- **公式ドキュメントへのリンク**: [Get text embeddings](https://cloud.google.com/vertex-ai/generative-ai/docs/embeddings/get-text-embeddings) 28,([https://cloud.google.com/vertex-ai/generative-ai/docs/model-reference/text-embeddings-api](https://cloud.google.com/vertex-ai/generative-ai/docs/model-reference/text-embeddings-api)) 29
- **調査元URL/公開日**: 23 (2025-06-06)

`gemini-embedding-001`は、Googleの最先端テキスト埋め込みモデルであり、最大3072次元のベクトルを生成できます 28。このモデルは、以前の専門モデル（`text-embedding-005`や`text-multilingual-embedding-002`）を統合し、それぞれのドメインでより優れたパフォーマンスを達成しています 28。特に、多言語およびコードタスクにおける最先端の性能は、幅広いグローバルなアプリケーションでの利用に適していることを示唆しています。

ユーザーが埋め込みベクトルの次元数を制御できる機能 28は、ストレージと計算リソースの最適化において重要な柔軟性を提供します。これは、OpenAIのMRL機能と同様に、ベクトルデータベースの効率的な運用を可能にし、大規模な検索システムやRAG（Retrieval Augmented Generation）アプリケーションのコストとパフォーマンスを最適化する上で役立ちます。

### Table 4: Google Gemini API 埋め込みモデル一覧

|   |   |   |   |   |   |   |
|---|---|---|---|---|---|---|
|**モデル名**|**モデルタイプ／ファミリ**|**埋め込みベクトル次元数**|**最大コンテキスト長（トークン）**|**料金（$/1Mトークン）**|**公式ドキュメントリンク**|**調査元URL/公開日**|
|gemini-embedding-001 (Text Embedding 004)|Embedding|最大3072 (ユーザーが制御可)|2048|未公開|[Link](https://cloud.google.com/vertex-ai/generative-ai/docs/embeddings/get-text-embeddings)|23|

### 2.3. Google Gemini API モデルの共通機能と料金体系の概要

Google Gemini APIは、柔軟な料金体系と、開発者がアプリケーションを構築するための多様な機能を統合しています。

- **料金体系**: ほとんどのGeminiモデルは従量課金制（pay-as-you-go）を採用しており、使用量に応じて課金されます 30。無料ティアも提供されており、特定のモデル（例: Gemini 2.5 Flash Preview）では入力と出力が無料で使用できます 23。
- **関数呼び出し**: Gemini APIは関数呼び出しをサポートしており、モデルがユーザーのプロンプトに基づいて外部ツールやAPIを呼び出すための構造化されたJSONオブジェクトを生成できます 26。これにより、モデルはリアルタイムデータへのアクセスや特定のアクションの実行が可能になり、より強力なエージェントアプリケーションの構築が容易になります。
- **ファインチューニング**: Gemini APIはファインチューニング（教師ありファインチューニングとも呼ばれる）をサポートしており、モデルのパフォーマンスを特定のタスクや出力要件に合わせて改善できます 31。最小20例からファインチューニングが可能であり、データセットの品質と多様性が重要です 31。ただし、ファインチューニングされたモデルには、入力文字数制限やJSONモード・システム指示の未サポートなどの制限があります 31。また、一部のモデル（例: Gemini 2.5 Flash Preview, Pro Preview）ではファインチューニングがサポートされていません 23。
- **レイテンシとスループット**: 大規模なプロンプト（100Kトークン以上）では、Gemini 2.5 Pro Previewなどのモデルで高レイテンシが発生する可能性があります 24。Googleは、専用リソースを提供するVertex AI Provisioned Throughputや、出力長の最適化、キャッシング、チャンキングなどのアプローチを通じてレイテンシを削減する方法を推奨しています 24。
- **公式ドキュメントへのリンク**: [Gemini API Pricing](https://ai.google.dev/gemini-api/docs/pricing) 23, [Function Calling with the Gemini API](https://ai.google.dev/gemini-api/docs/function-calling) 27,([https://ai.google.dev/gemini-api/docs/model-tuning](https://ai.google.dev/gemini-api/docs/model-tuning)) 31
- **調査元URL/公開日**: 23 (2025-06-06), 23 (2025-06-06), 23 (2025-06-06), 31 (2025-04-16), 25 (2025-06-09), 31 (2025-04-16)

Google Gemini APIは、コスト効率とスケーラビリティに重点を置いています。従量課金制と無料ティアの提供 23は、開発者が小規模なプロジェクトから大規模なデプロイメントまで、コストを管理しながらAIモデルを試用・利用できる環境を整えています。特に、大規模なコンテキスト処理におけるレイテンシの課題に対して、専用スループットや最適化手法を提案している点 24は、Googleがエンタープライズレベルのニーズに対応しようとしていることを示しています。

また、Googleは機能性と責任あるAIのバランスにも注力しています。関数呼び出しのサポート 26は、モデルが外部ツールと連携し、より複雑なタスクを実行できる能力を強化します。一方で、モデルの利用規約において「Google製品の改善に使用されるか否か」という項目が無料ティアで「はい」となっていること 23は、データ利用に関する透明性を提供し、責任あるAI開発へのコミットメントを示しています。これは、ユーザーが自身のデータの利用方法について情報に基づいた意思決定を行う上で重要な要素となります。

## III. Ollama CLI（ローカル／リモートモデル）

Ollamaは、オープンソースの言語モデルをローカル環境で簡単に実行できるプラットフォームであり、CLIを通じて多様なモデルへのアクセスを提供します。これにより、開発者はプライバシーを保護しつつ、カスタマイズされたAIソリューションを柔軟に構築できます。

### 3.1. テキスト生成モデル (Completion Models) の詳細

Ollamaは、Llama、Mistral、Gemmaなど、多岐にわたるオープンソースのテキスト生成モデルをサポートしています。これらのモデルは、パラメータ数、サイズ、コンテキスト長、および特定の機能において多様な選択肢を提供します。

Ollamaのモデルライブラリは非常に広範であり、以下に主要なモデルファミリーとその特徴を概説します。詳細なモデルリストはTable 5を参照してください。

- **Llamaファミリー**: Metaが開発した基盤モデル群で、7Bから405Bまでの幅広いパラメータサイズがあります 33。`llama3.3`は最新の70Bモデルで、`llama3.1 405B`モデルに匹敵する性能を提供します 35。`llama3-gradient`は、Llama-3 8Bのコンテキスト長を100万トークン以上に拡張するモデルです 35。`llama3.2-vision`は、テキストと画像の両方を処理できるマルチモーダルな推論モデルです 35。
- **Mistralファミリー**: Mistral AIが開発したモデル群で、効率性と性能を両立させています 33。`mixtral`は、Mixture of Experts (MoE) アーキテクチャを採用し、8x7bおよび8x22bのパラメータサイズがあります 35。`mistral-large`は、コード生成、数学、推論能力が大幅に向上した主力モデルです 35。
- **Gemmaファミリー**: Google DeepMindが開発した軽量で高性能なオープンモデルです 33。`gemma3`は、1Bから27Bまでのパラメータサイズがあり、単一GPUで実行可能な最も有能なモデルとされています 33。
- **Phiファミリー**: Microsoftが開発した小型で高性能なモデルです 33。`phi4-mini`は、多言語サポート、推論、数学、関数呼び出し機能が強化されています 34。
- **Code特化モデル**: `codellama` 33, `codestral` 34, `qwen2.5-coder` 35, `deepseek-coder` 35など、コード生成や理解に特化したモデルも多数提供されています。
- **マルチモーダルモデル**: `llava` 33, `moondream` 33, `minicpm-v` 35, `bakllava` 35など、画像やその他の視覚情報を処理できるモデルも利用可能です。
- **その他**: `deepseek-r1` (推論モデル) 33, `qwen3` (思考モードと非思考モードを切り替え可能) 34, `command-r` (RAGとツール使用に最適化) 35, `hermes3` (エージェント能力と関数呼び出しを強化) 35など、特定の用途や機能に特化した多様なモデルが存在します。

これらのモデルは、OllamaのCLIを通じて簡単にプルして実行できます。例えば、`ollama run <model-name>`コマンドを使用します 33。Ollamaは、モデルをメモリにマッピングすることで、必要な部分のみをロードする効率的なメモリ管理も行います 36。

### Table 5: Ollama CLI テキスト生成モデル一覧

|   |   |   |   |   |   |
|---|---|---|---|---|---|
|**モデル名（API 上の正式な識別子）**|**モデルタイプ／ファミリ**|**最大コンテキスト長（トークン）**|**サポートされる主要機能**|**公式ドキュメントリンク**|**調査元URL/公開日**|
|llama4|Llama 4|未公開 (128K+, 400Bモデルは160K)|マルチモーダル (テキスト, 画像), ツール使用|[Link](https://ollama.com/library/llama4)|33|
|llama3.3|Llama 3.3|128,000|多言語, 長文コンテキスト, ツール連携|[Link](https://ollama.com/library/llama3.3)|33|
|llama3.2|Llama 3.2|128,000|多言語, 指示追従, 要約, ツール使用|[Link](https://ollama.com/library/llama3.2)|33|
|llama3.2-vision|Llama 3.2 Vision|128,000|マルチモーダル (テキスト, 画像), 視覚認識, 画像推論, キャプション|[Link](https://ollama.com/library/llama3.2-vision)|33|
|llama3.1|Llama 3.1|128,000|多言語, 長文コンテキスト, ツール使用, 推論強化|[Link](https://ollama.com/library/llama3.1)|33|
|llama3|Llama 3|8,000|対話, チャット, API対応|[Link](https://ollama.com/library/llama3)|35|
|llama2|Llama 2|4,096|チャット, テキスト生成|[Link](https://ollama.com/library/llama2)|35|
|mistral|Mistral|32,000|関数呼び出し, テキスト補完, 指示追従|[Link](https://ollama.com/library/mistral)|33|
|mixtral|Mixtral (MoE)|32,000 (8x7b), 64,000 (8x22b)|多言語, 数学, コーディング, 関数呼び出し|[Link](https://ollama.com/library/mixtral)|34|
|gemma3|Gemma 3|32,000 (1b), 128,000 (4b, 12b, 27b)|マルチモーダル (テキスト, 画像), 質問応答, 要約, 推論|[Link](https://ollama.com/library/gemma3)|33|
|gemma2|Gemma 2|未公開|テキスト生成, チャットボット, 要約|[Link](https://ollama.com/library/gemma2)|35|
|phi4|Phi 4|16,000|推論, 論理, 一般目的AIシステム|[Link](https://ollama.com/library/phi4)|33|
|phi4-mini|Phi 4 Mini|128,000|多言語, 推論, 数学, 関数呼び出し|[Link](https://ollama.com/library/phi4-mini)|34|
|codellama|Code Llama|16,000 (7b, 13b, 34b), 2,000 (70b)|コード生成, コード説明, FIM, コードレビュー, テスト作成|[Link](https://ollama.com/library/codellama)|33|
|qwen3|Qwen3|40,000|思考モード/非思考モード, 推論強化, エージェント機能, 多言語|[Link](https://ollama.com/library/qwen3)|34|
|command-r|Command R|128,000|RAG, ツール使用, 多言語, 会話|[Link](https://ollama.com/library/command-r)|35|
|command-r-plus|Command R+|128,000|RAG (引用機能付き), 多言語, ツール使用|[Link](https://ollama.com/library/command-r-plus)|35|
|wizardlm2|WizardLM-2|32,000 (7b), 64,000 (8x22b)|チャット, 多言語, 推論, エージェント|[Link](https://ollama.com/library/wizardlm2)|35|
|hercules2|Hercules 2.0|8,000|未公開|[Link](https://www.google.com/search?q=https://ollama.com/library/hercules2)|35|
|deepseek-r1|DeepSeek-R1|128,000 (一部), 160,000 (671b)|推論, 数学, プログラミング|[Link](https://ollama.com/library/deepseek-r1)|33|
|qwen2.5vl|Qwen2.5-VL|125,000|視覚理解, エージェント機能, 視覚的ローカライゼーション, 構造化出力|[Link](https://ollama.com/library/qwen2.5vl)|34|
|devstral|Devstral|128,000|ソフトウェアエンジニアリングタスク, コーディングエージェント, ツール使用|[Link](https://ollama.com/library/devstral)|34|
|cogito|Cogito|128,000|ハイブリッド推論 (直接回答/自己反省), コーディング, STEM, ツール呼び出し|[Link](https://ollama.com/library/cogito)|34|
|exaone-deep|EXAONE Deep|32,000|推論, 数学, コーディング|[Link](https://ollama.com/library/exaone-deep)|34|
|magistral|Magistral|39,000 (推奨)|推論, 多言語, ビジネス戦略, 規制産業, ソフトウェアエンジニアリング|[Link](https://ollama.com/library/magistral)|34|
|command-a|Command A|16,000|会話, RAG, ツールサポート, コード|[Link](https://ollama.com/library/command-a)|34|
|command-r7b-arabic|Command R7B Arabic|16,000|高度なアラビア語能力, RAG (引用機能付き)|[Link](https://ollama.com/library/command-r7b-arabic)|34|
|qwen2.5-coder|Qwen2.5 Coder|32,000|コード生成, コード推論, コード修正|[Link](https://ollama.com/library/qwen2.5-coder)|35|
|llava|LLaVA|32,000 (7b), 4,000 (13b, 34b)|マルチモーダル (テキスト, 画像), 視覚推論, OCR|[Link](https://ollama.com/library/llava)|35|
|moondream|Moondream 2|2,000|小型視覚言語モデル, エッジデバイス向け|[Link](https://ollama.com/library/moondream)|33|
|dbrx|DBRX (MoE)|未公開|コーディング, 一般目的LLM|[Link](https://ollama.com/library/dbrx)|35|

### 3.2. 埋め込みモデル (Embedding Models) の詳細

Ollamaは、テキスト埋め込みのための複数のオープンソースモデルも提供しており、それぞれ異なる性能と次元数を持っています。

- **nomic-embed-text**: 高性能なオープン埋め込みモデルで、大きなトークンコンテキストウィンドウを特徴とします 37。OpenAIの`text-embedding-ada-002`や`text-embedding-3-small`を上回る性能を持つとされています 37。
    - **埋め込みベクトル次元数**: 768次元 38。V2では768から256次元への次元削減も可能 39。
    - **最大コンテキスト長**: 2Kトークン 37。
- **mxbai-embed-large**: mixedbread.aiによって開発された最先端の大型埋め込みモデルです 35。OpenAIの`text-embedding-3-large`を上回り、その20倍のサイズのモデルに匹敵する性能を持つとされています 35。
    - **埋め込みベクトル次元数**: 1024次元 40。
    - **最大コンテキスト長**: 512トークン 35。
- **bge-m3**: BAAIによって開発された埋め込みモデルで、多機能性、多言語性、多粒度性を特徴とします 35。
    - **埋め込みベクトル次元数**: 1024次元 42。
    - **最大コンテキスト長**: 8192トークン 42。
- **all-minilm**: 大規模な文レベルデータセットで訓練された埋め込みモデルです 35。
    - **埋め込みベクトル次元数**: 384次元 38。
    - **最大コンテキスト長**: 512トークン 35。
- **paraphrase-multilingual**: 文や段落を768次元の密なベクトル空間にマッピングするSentence-transformersモデルです 44。
    - **埋め込みベクトル次元数**: 768次元 44。
    - **最大コンテキスト長**: 512トークン 44。
- **snowflake-arctic-embed**: Snowflakeによる高性能なテキスト埋め込みモデル群です 35。
    - **埋め込みベクトル次元数**: 22Mモデルは384次元、110Mモデルは768次元、335Mモデルは1024次元 46。
    - **最大コンテキスト長**: 512トークン (一部2Kトークン) 47。
- **snowflake-arctic-embed2**: Snowflakeの最新の埋め込みモデルで、多言語対応を含みます 35。
    - **埋め込みベクトル次元数**: 1024次元 48。
    - **最大コンテキスト長**: 8Kトークン 49。
- **granite-embedding**: IBM Researchによるテキスト専用の埋め込みモデルです 35。
    - **埋め込みベクトル次元数**: 30Mモデルは384次元、278Mモデルは768次元 50。
    - **最大コンテキスト長**: 未公開。

これらの埋め込みモデルは、ローカルで実行できるため、特にデータプライバシーが懸念されるアプリケーションや、オフライン環境での利用に適しています。また、OllamaのAPIを通じて簡単にアクセスでき、PythonやJavaScriptライブラリからも利用可能です 37。

### Table 6: Ollama CLI 埋め込みモデル一覧

|   |   |   |   |   |   |
|---|---|---|---|---|---|
|**モデル名（API 上の正式な識別子）**|**モデルタイプ／ファミリ**|**埋め込みベクトル次元数**|**最大コンテキスト長（トークン）**|**公式ドキュメントリンク**|**調査元URL/公開日**|
|nomic-embed-text|Embedding|768 (V2は256にトリミング可)|2,000|[Link](https://ollama.com/library/nomic-embed-text)|37|
|mxbai-embed-large|Embedding|1,024|512|[Link](https://ollama.com/library/mxbai-embed-large)|35|
|bge-m3|Embedding|1,024|8,192|[Link](https://ollama.com/library/bge-m3)|35|
|all-minilm|Embedding|384|512|[Link](https://ollama.com/library/all-minilm)|35|
|paraphrase-multilingual|Embedding|768|512|[Link](https://ollama.com/library/paraphrase-multilingual)|35|
|snowflake-arctic-embed|Embedding|384, 768, 1024 (モデルによる)|512 (一部2K)|[Link](https://ollama.com/library/snowflake-arctic-embed)|35|
|snowflake-arctic-embed2|Embedding|1,024|8,000|[Link](https://ollama.com/library/snowflake-arctic-embed2)|35|
|granite-embedding|Embedding|384, 768 (モデルによる)|未公開|[Link](https://ollama.com/library/granite-embedding)|35|

### 3.3. Ollama CLI モデルの共通機能と料金体系の概要

Ollamaは、オープンソースモデルの実行と管理を簡素化するツールであり、ローカル環境でのAI活用を強力に推進します。

- **ローカル／リモートモデルの実行**: Ollamaは、ユーザーが様々なAIモデルをローカルで実行できるように設計されています 36。これにより、インターネット接続なしでモデルを利用できるほか、データプライバシーを確保し、APIコストを削減できます。また、リモートサーバー上のOllamaインスタンスに接続してモデルを実行することも可能です。
- **API互換性**: OllamaはOpenAI APIと互換性のあるAPIを提供しており、既存のOpenAIアプリケーションからの移行や統合を容易にします 52。`curl`コマンド、Pythonライブラリ、JavaScriptライブラリを通じてモデルにアクセスできます 37。
- **ストリーミング**: Ollamaはツール呼び出しを含むストリーミング応答をサポートしており、チャットアプリケーションがリアルタイムでコンテンツをストリーミングしたり、ツールを呼び出したりすることを可能にします 53。これにより、ユーザー体験が向上し、応答性の高いアプリケーションを構築できます。
- **ファインチューニングのサポート**: Ollamaは、SafetensorsウェイトやGGUFファイルからのファインチューニングされたアダプターやモデルのインポートをサポートしています 52。Llama、Mistral、Gemma、Phi3などの主要なモデルアーキテクチャに対応しており、ユーザーは自身のデータでモデルをカスタマイズできます 52。また、FP16やFP32ベースのモデルを異なる量子化レベルに変換する機能も提供しています 52。
- **関数呼び出し**: Ollamaは関数呼び出し機能をサポートしており、モデルが外部ツールやAPIと連携してタスクを実行できるようにします 51。これにより、より複雑なエージェントアプリケーションや自動化ワークフローをローカルで構築することが可能になります。
- **料金**: Ollama自体はオープンソースであり、モデルの実行には直接的な料金は発生しません。ただし、ローカルでの実行には、適切なハードウェア（CPU、RAM、GPU）への初期投資が必要です。モデルのサイズに応じて、必要なRAMの目安が示されています（例: 7Bモデルで8GB、13Bモデルで16GB、70Bモデルで64GB） 35。
- **公式ドキュメントへのリンク**: [Ollama GitHub](https://github.com/ollama/ollama) 33, [Ollama Library](https://ollama.com/library) 34, [Importing models](https://ollama.readthedocs.io/en/import/) 52
- **調査元URL/公開日**: 33

Ollamaは、オープンソースエコシステムの多様性とアクセス性を象徴しています。OpenAIやGoogleが提供する商用APIとは異なり、OllamaはLlama、Mistral、Gemmaなど、多岐にわたるオープンソースモデルをサポートし 33、これらをローカル環境で実行できる柔軟性を提供します 36。これにより、開発者は特定のユースケースに最適なモデルを自由に選択し、ベンダーロックインのリスクを回避できます。また、モデルライブラリの継続的な拡大は、オープンソースコミュニティの活発な活動と、AI技術の民主化への貢献を示しています。

Ollamaの最も重要な利点の一つは、ローカル推論とカスタマイズの可能性です。モデルをローカルで実行できるため、データプライバシーが厳しく求められる環境や、インターネット接続が不安定な状況でもAIを活用できます。さらに、ファインチューニング機能 52と関数呼び出し機能 51のサポートは、開発者が自身のデータとニーズに合わせてモデルを高度にカスタマイズし、特定のビジネスロジックや外部システムと統合したAIアプリケーションを構築できることを意味します。これにより、AIの応用範囲が広がり、よりパーソナライズされた、効率的なソリューションの実現が可能になります。

## 結論

本レポートでは、OpenAI API、Google Gemini API、およびOllama CLIの3つの主要なAIプラットフォームにおけるテキスト生成モデルと埋め込みモデルの詳細な比較分析を行いました。各プラットフォームは異なる強みと戦略を持ち、多様な開発ニーズに対応しています。

**OpenAI API**は、GPT-4oやGPT-4.1ファミリーに見られるように、マルチモーダル能力、大規模なコンテキストウィンドウ、および高度なエージェント機能に注力しています。特に、GPT-4.1ファミリーの100万トークンを超えるコンテキスト長は、複雑な長文処理やエージェントベースのアプリケーションに大きな優位性をもたらします。料金体系はモデルの性能と機能に応じて階層化されており、ファインチューニングや多様なツール呼び出しをサポートすることで、エンタープライズレベルのデプロイメントを促進しています。埋め込みモデルにおいては、MRLによる次元削減機能がストレージと計算効率の向上に貢献し、多言語対応の強化も進んでいます。

**Google Gemini API**は、特にGemini 1.5 Proの200万トークンという画期的なコンテキストウィンドウで際立っています。これは、極めて大規模なデータセットの処理を可能にします。Gemini 2.5 Flash Previewの「思考」トークンに対する課金は、モデルの内部推論プロセスをコスト最適化の対象とするユニークなアプローチです。Googleはまた、マルチモーダルな入力処理と、Google Searchとの連携（Grounding）を通じて、モデルの汎用性と実用性を高めています。レイテンシの課題は存在しますが、Provisioned Throughputなどのソリューションを提供し、大規模利用への対応を進めています。ファインチューニングは一部のモデルでサポートされていますが、OpenAIに比べて制限が多い点も見られます。

**Ollama CLI**は、オープンソースAIモデルのローカル実行とカスタマイズにおいて比類ない柔軟性を提供します。Llama、Mistral、Gemmaなど、多様なテキスト生成モデルと埋め込みモデルをサポートし、データプライバシーを重視する環境やオフラインでの利用を可能にします。OllamaのAPIはOpenAI APIと互換性があり、ストリーミングや関数呼び出しもサポートしているため、オープンソースモデルを既存のインフラストラクチャに容易に統合できます。ファインチューニング機能は、ユーザーが自身のデータでモデルを微調整し、特定のユースケースに最適化できる強力な手段となります。直接的なAPIコストはかかりませんが、ローカルハードウェアへの投資が必要となります。

**推奨事項**:

- **最先端のマルチモーダル機能とエージェント機能、および長大なコンテキスト長を重視する場合**: OpenAI APIのGPT-4oおよびGPT-4.1ファミリーが最適な選択肢となるでしょう。特に、複雑なエージェントワークフローや高度なコード生成、指示追従を必要とする場合に強みを発揮します。
- **極めて大規模なコンテキスト処理能力とコスト効率を重視し、思考プロセスを制御したい場合**: Google Gemini APIのGemini 1.5 ProやGemini 2.5 Flashが有力な選択肢となります。特に、超長文のデータ分析や、思考ステップにコストを最適化したい場合に適しています。
- **データプライバシー、オフライン利用、コスト管理、およびオープンソースモデルの柔軟なカスタマイズを重視する場合**: Ollama CLIが最適なソリューションです。ローカル環境での開発や、特定のドメインに特化したモデルのファインチューニング、または複数のモデルを柔軟に試したい場合に非常に有効です。

最終的なモデル選択は、プロジェクトの具体的な要件、予算、必要な性能レベル、デプロイメント環境、およびデータプライバシー要件に基づいて慎重に行われるべきです。本レポートが、これらの複雑な選択プロセスにおける客観的な情報源として機能することを期待します。